{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM6OOQuHLrbpCEf2o8XcMDO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Su-ok/MT2025124_ML_Project2/blob/main/BinLogistic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GzWO89D1je7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50738e46-2269-4462-bf00-7a0af43e6e51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "np.random.seed(42)\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# ==== LOAD DATA ====\n",
        "train_path = \"/content/drive/MyDrive/ML kaggle data/smoker/train_dataset.csv\"\n",
        "test_path  = \"/content/drive/MyDrive/ML kaggle data/smoker/test_dataset.csv\"\n",
        "\n",
        "train = pd.read_csv(train_path)\n",
        "test  = pd.read_csv(test_path)\n",
        "\n",
        "print(\"Original train shape:\", train.shape)\n",
        "\n",
        "# Identify feature columns\n",
        "target_col = \"smoking\"\n",
        "feature_cols = [c for c in train.columns if c != target_col]\n",
        "\n",
        "# ==== 1) DETECT DUPLICATES ====\n",
        "exact_dup_mask = train.duplicated(subset=feature_cols + [target_col], keep=False)\n",
        "feat_dup_mask  = train.duplicated(subset=feature_cols, keep=False)\n",
        "\n",
        "print(\"Exact duplicates:\", exact_dup_mask.sum())\n",
        "print(\"Feature duplicates:\", feat_dup_mask.sum())\n",
        "\n",
        "# ==== 2) RESOLVE DUPLICATES =====\n",
        "grouped = train.groupby(feature_cols)[target_col].agg(\n",
        "    n_samples      ='size',\n",
        "    unique_labels  =lambda s: s.unique().tolist(),\n",
        "    label_counts   =lambda s: s.value_counts().to_dict()\n",
        ").reset_index()\n",
        "\n",
        "rows = []\n",
        "resolved_majority = 0\n",
        "removed_ties = 0\n",
        "\n",
        "for _, row in grouped.iterrows():\n",
        "    feat_vals = {c: row[c] for c in feature_cols}\n",
        "    labels = row[\"unique_labels\"]\n",
        "    counts = row[\"label_counts\"]\n",
        "\n",
        "    if len(labels) == 1:\n",
        "        # pure duplicates → keep one representative\n",
        "        rows.append({**feat_vals, target_col: labels[0]})\n",
        "    else:\n",
        "        # conflicting labels → majority vote if unique\n",
        "        max_count = max(counts.values())\n",
        "        majority_labels = [lbl for lbl, cnt in counts.items() if cnt == max_count]\n",
        "\n",
        "        if len(majority_labels) == 1:\n",
        "            rows.append({**feat_vals, target_col: majority_labels[0]})\n",
        "            resolved_majority += 1\n",
        "        else:\n",
        "            # tie → drop group entirely\n",
        "            removed_ties += row[\"n_samples\"]\n",
        "\n",
        "print(\"\\nResolved by unique majority:\", resolved_majority)\n",
        "print(\"Dropped conflicting groups:\", removed_ties)\n",
        "\n",
        "clean_train = pd.DataFrame(rows)\n",
        "print(\"\\nCleaned train shape:\", clean_train.shape)\n",
        "\n",
        "# ==== 3) PREPARE DATA ====\n",
        "X = clean_train[feature_cols].values\n",
        "y = clean_train[target_col].values\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "test_scaled = scaler.transform(test[feature_cols].values)\n",
        "\n",
        "# ==== 4) TRAIN–VALIDATION SPLIT ====\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "print(\"X_train:\", X_train.shape, \"X_val:\", X_val.shape)\n",
        "\n",
        "# ==== 5) LOGISTIC REGRESSION + RANDOM SEARCH ====\n",
        "logreg = LogisticRegression(max_iter=5000)\n",
        "\n",
        "param_dist = {\n",
        "    \"C\": [0.01, 0.1, 1.0, 10.0],\n",
        "    \"solver\": [\"lbfgs\", \"liblinear\"],\n",
        "}\n",
        "\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "logreg_search = RandomizedSearchCV(\n",
        "    estimator=logreg,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=8,                  # only 8 unique combos → 8 iterations max\n",
        "    scoring=\"accuracy\",\n",
        "    n_jobs=-1,\n",
        "    cv=cv,\n",
        "    random_state=42,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "print(\"\\n=== Starting RandomizedSearchCV for Logistic Regression ===\")\n",
        "logreg_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\nBest Params:\", logreg_search.best_params_)\n",
        "print(\"Best CV Accuracy:\", logreg_search.best_score_)\n",
        "\n",
        "best_logreg = logreg_search.best_estimator_\n",
        "\n",
        "# ==== 6) EVALUATION ====\n",
        "y_train_pred = best_logreg.predict(X_train)\n",
        "y_val_pred   = best_logreg.predict(X_val)\n",
        "\n",
        "print(\"\\nTraining Accuracy:\", accuracy_score(y_train, y_train_pred))\n",
        "print(\"Validation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
        "\n",
        "# print(\"\\nClassification Report:\")\n",
        "# print(classification_report(y_val, y_val_pred))\n",
        "\n",
        "# print(\"\\nConfusion Matrix:\")\n",
        "# print(confusion_matrix(y_val, y_val_pred))\n",
        "\n",
        "# ==== 7) FINAL TRAINING ON FULL DATA & SUBMISSION ====\n",
        "best_logreg.fit(X_scaled, y)\n",
        "\n",
        "test_preds = best_logreg.predict(test_scaled)\n",
        "\n",
        "submission = pd.DataFrame({\"smoking\": test_preds})\n",
        "submission.to_csv(\"submission_logreg_smoker.csv\", index=False)\n",
        "\n",
        "print(\"\\nSaved submission_logreg_smoker.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8JhFO2lMcfe",
        "outputId": "b8a2d2bd-45de-4d9f-85bf-f6131b3821c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original train shape: (38984, 23)\n",
            "Exact duplicates: 11034\n",
            "Feature duplicates: 11034\n",
            "\n",
            "Resolved by unique majority: 0\n",
            "Dropped conflicting groups: 0\n",
            "\n",
            "Cleaned train shape: (33467, 23)\n",
            "X_train: (26773, 22) X_val: (6694, 22)\n",
            "\n",
            "=== Starting RandomizedSearchCV for Logistic Regression ===\n",
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
            "\n",
            "Best Params: {'solver': 'liblinear', 'C': 10.0}\n",
            "Best CV Accuracy: 0.7196055622308687\n",
            "\n",
            "Training Accuracy: 0.7212863705972435\n",
            "Validation Accuracy: 0.7260233044517478\n",
            "\n",
            "Saved submission_logreg_smoker.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_val, y_val_pred))\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_val, y_val_pred))"
      ],
      "metadata": {
        "id": "OhLht72INMOr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f442bb44-5efa-4820-ee4a-5a1aee23a55f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.83      0.79      4242\n",
            "           1       0.65      0.55      0.60      2452\n",
            "\n",
            "    accuracy                           0.73      6694\n",
            "   macro avg       0.70      0.69      0.69      6694\n",
            "weighted avg       0.72      0.73      0.72      6694\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[3512  730]\n",
            " [1104 1348]]\n"
          ]
        }
      ]
    }
  ]
}