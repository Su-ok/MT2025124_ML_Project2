{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNY1FsSbbJ2nEs0rTM7iyml",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Su-ok/MT2025124_ML_Project2/blob/main/BinNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClFeIFxGMhKx",
        "outputId": "c9df71fa-4c73-49f3-dc11-8b86b3bf6a72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== IMPORTS ====\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "# ==== LOAD DATA ====\n",
        "train_path = \"/content/drive/MyDrive/ML kaggle data/smoker/train_dataset.csv\"\n",
        "test_path  = \"/content/drive/MyDrive/ML kaggle data/smoker/test_dataset.csv\"\n",
        "\n",
        "train=pd.read_csv(train_path)\n",
        "test=pd.read_csv(test_path)\n",
        "print(\"Original train shape:\", train.shape)\n",
        "\n",
        "# Identify feature columns\n",
        "target_col=\"smoking\"\n",
        "feature_cols=[c for c in train.columns if c!=target_col]\n",
        "\n",
        "# === 1) Detect duplicates ===\n",
        "exact_dup_mask = train.duplicated(subset=feature_cols + [target_col], keep=False)\n",
        "feat_dup_mask  = train.duplicated(subset=feature_cols, keep=False)\n",
        "\n",
        "print(\"Exact duplicates:\", exact_dup_mask.sum())\n",
        "print(\"Feature duplicates:\", feat_dup_mask.sum())\n",
        "\n",
        "# ==== 2) RESOLVE DUPLICATES =====\n",
        "grouped = train.groupby(feature_cols)[target_col].agg(\n",
        "    n_samples      ='size',\n",
        "    unique_labels  =lambda s: s.unique().tolist(),\n",
        "    label_counts   =lambda s: s.value_counts().to_dict()\n",
        ").reset_index()\n",
        "\n",
        "rows = []\n",
        "resolved_majority = 0\n",
        "removed_ties = 0\n",
        "\n",
        "for _, row in grouped.iterrows():\n",
        "    feat_vals = {c: row[c] for c in feature_cols}\n",
        "    labels = row[\"unique_labels\"]\n",
        "    counts = row[\"label_counts\"]\n",
        "\n",
        "    if len(labels) == 1:\n",
        "        # pure duplicates → keep one representative\n",
        "        rows.append({**feat_vals, target_col: labels[0]})\n",
        "    else:\n",
        "        # conflicting labels → majority vote if unique\n",
        "        max_count = max(counts.values())\n",
        "        majority_labels = [lbl for lbl, cnt in counts.items() if cnt == max_count]\n",
        "\n",
        "        if len(majority_labels) == 1:\n",
        "            rows.append({**feat_vals, target_col: majority_labels[0]})\n",
        "            resolved_majority += 1\n",
        "        else:\n",
        "            # tie → drop group entirely\n",
        "            removed_ties += row[\"n_samples\"]\n",
        "\n",
        "print(\"\\nResolved by unique majority:\", resolved_majority)\n",
        "print(\"Dropped conflicting groups:\", removed_ties)\n",
        "\n",
        "clean_train = pd.DataFrame(rows)\n",
        "print(\"\\nCleaned train shape:\", clean_train.shape)\n",
        "\n",
        "# ==== 3) PREPARE DATA ====\n",
        "X = clean_train[feature_cols].values\n",
        "y = clean_train[target_col].values\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "test_scaled = scaler.transform(test[feature_cols].values)\n",
        "\n",
        "# Stratified Train–Validation split\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_scaled,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "print(\"X_train:\", X_train.shape, \"X_val:\", X_val.shape)\n",
        "\n",
        "# ==== DEFINE NEURAL NETWORK MODEL ====\n",
        "mlp = MLPClassifier(\n",
        "    hidden_layer_sizes=(32, 16),   # 2 hidden layers\n",
        "    activation=\"relu\",\n",
        "    solver=\"adam\",\n",
        "    alpha=0.001,\n",
        "    max_iter=300,\n",
        "    learning_rate_init=0.001,\n",
        "    early_stopping=True,           # stops when validation stops improving\n",
        "    n_iter_no_change=10,\n",
        "    validation_fraction=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"\\nTraining Neural Network using adam...\")\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "# ==== EVALUATION ====\n",
        "y_train_pred = mlp.predict(X_train)\n",
        "y_val_pred   = mlp.predict(X_val)\n",
        "\n",
        "train_acc = accuracy_score(y_train, y_train_pred)\n",
        "val_acc   = accuracy_score(y_val, y_val_pred)\n",
        "\n",
        "print(f\"\\nTraining Accuracy (MLP):   {train_acc:.6f}\")\n",
        "print(f\"Validation Accuracy (MLP): {val_acc:.6f}\")\n",
        "\n",
        "# print(\"\\nClassification Report:\")\n",
        "# print(classification_report(y_val, y_val_pred))\n",
        "\n",
        "# print(\"\\nConfusion Matrix:\")\n",
        "# print(confusion_matrix(y_val, y_val_pred))\n",
        "\n",
        "# ==== FINAL TRAINING ON FULL DATA ====\n",
        "mlp_final = MLPClassifier(\n",
        "    hidden_layer_sizes=(32, 16),\n",
        "    activation=\"relu\",\n",
        "    solver=\"adam\",\n",
        "    alpha=0.001,\n",
        "    max_iter=300,\n",
        "    learning_rate_init=0.001,\n",
        "    early_stopping=True,           # stops when validation stops improving\n",
        "    n_iter_no_change=10,\n",
        "    validation_fraction=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "mlp_final.fit(X_scaled, y)\n",
        "\n",
        "# Predict on test\n",
        "test_preds = mlp_final.predict(test_scaled)\n",
        "\n",
        "# Create submission CSV\n",
        "submission = pd.DataFrame({\n",
        "    \"smoking\": test_preds\n",
        "})\n",
        "\n",
        "submission.to_csv(\"submission_nn_smoker.csv\", index=False)\n",
        "print(\"\\nsubmission_nn_smoker.csv created successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p043EmJNNESg",
        "outputId": "20b28775-3794-458a-8416-3bc4c7821331"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original train shape: (38984, 23)\n",
            "Exact duplicates: 11034\n",
            "Feature duplicates: 11034\n",
            "\n",
            "Resolved by unique majority: 0\n",
            "Dropped conflicting groups: 0\n",
            "\n",
            "Cleaned train shape: (33467, 23)\n",
            "X_train: (26773, 22) X_val: (6694, 22)\n",
            "\n",
            "Training Neural Network using adam...\n",
            "\n",
            "Training Accuracy (MLP):   0.759833\n",
            "Validation Accuracy (MLP): 0.747386\n",
            "\n",
            "submission_nn_smoker.csv created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_val, y_val_pred))\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_val, y_val_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r46OIhePw3ai",
        "outputId": "f0c0c670-0b10-40e3-ecdf-3cc2d9118830"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.82      0.81      4242\n",
            "           1       0.67      0.62      0.64      2452\n",
            "\n",
            "    accuracy                           0.75      6694\n",
            "   macro avg       0.73      0.72      0.72      6694\n",
            "weighted avg       0.74      0.75      0.74      6694\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[3495  747]\n",
            " [ 944 1508]]\n"
          ]
        }
      ]
    }
  ]
}